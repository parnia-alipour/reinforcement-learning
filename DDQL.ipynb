{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T15:45:58.049390Z",
     "start_time": "2026-01-11T15:45:58.045113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "import gym\n",
    "import gymnasium\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from collections import deque"
   ],
   "id": "410799553c184655",
   "outputs": [],
   "execution_count": 173
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T15:45:58.284426Z",
     "start_time": "2026-01-11T15:45:58.280496Z"
    }
   },
   "cell_type": "code",
   "source": "env=gymnasium.make('MountainCar-v0',render_mode='human')",
   "id": "27cedc4d7c0b9a9",
   "outputs": [],
   "execution_count": 174
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T15:45:58.554538Z",
     "start_time": "2026-01-11T15:45:58.532355Z"
    }
   },
   "cell_type": "code",
   "source": "env.reset().reshape()",
   "id": "2aa4932b7742d606",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[175]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43menv\u001B[49m\u001B[43m.\u001B[49m\u001B[43mreset\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mreshape\u001B[49m()\n",
      "\u001B[31mAttributeError\u001B[39m: 'tuple' object has no attribute 'reshape'"
     ]
    }
   ],
   "execution_count": 175
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T15:41:35.803908Z",
     "start_time": "2026-01-11T15:41:35.797256Z"
    }
   },
   "cell_type": "code",
   "source": "env.render()",
   "id": "37afb5c9ed53050",
   "outputs": [],
   "execution_count": 160
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T15:41:36.157213Z",
     "start_time": "2026-01-11T15:41:36.153271Z"
    }
   },
   "cell_type": "code",
   "source": "env.observation_space.shape[0]",
   "id": "a162bb263a98a831",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 161
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T15:41:36.493061Z",
     "start_time": "2026-01-11T15:41:36.488831Z"
    }
   },
   "cell_type": "code",
   "source": "env.action_space.n\n",
   "id": "224a5ab6a1cb5f29",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(3)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 162
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T15:41:36.805218Z",
     "start_time": "2026-01-11T15:41:36.800399Z"
    }
   },
   "cell_type": "code",
   "source": "env.action_space.sample()",
   "id": "60ff8c49c8d15bb3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 163
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T15:41:37.184785Z",
     "start_time": "2026-01-11T15:41:37.177108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DQN:\n",
    "    def __init__(self,env):\n",
    "        self.env=env\n",
    "        self.memory=deque(maxlen=2000)\n",
    "        self.gamma=0.03\n",
    "        self.epsilon=1.0\n",
    "        self.epsilon_min=0.01\n",
    "        self.epsilon_decay=0.995\n",
    "        self.learning_rate=0.005\n",
    "        self.tau=0.125\n",
    "        self.model=self.create_model()\n",
    "        self.target_model=self.create_model()\n",
    "    def create_model(self):\n",
    "            model=Sequential()\n",
    "            model.add(Dense(24,input_dim=self.env.observation_space.shape[0],activation='relu'))\n",
    "            model.add(Dense(48,activation='relu'))\n",
    "            model.add(Dense(24,activation='relu'))\n",
    "            model.add(Dense(self.env.action_space.n))\n",
    "            model.compile(loss='mean_squared_error', optimizer=Adam(lr=self.learning_rate))\n",
    "            return model\n",
    "    def act(self,state):\n",
    "            self.epsilon*=self.epsilon_dacay\n",
    "            self.epsilon=max(self.epsilon_min, self.epsilon)\n",
    "            if np.random.random()<self.epsilon:\n",
    "                return  self.env.action_space.sample()\n",
    "            else:\n",
    "                return np.argmax(self.model.predict(state))\n",
    "    def replay(self,state):\n",
    "            batch_size=32\n",
    "            if len(self.memory)<batch_size:\n",
    "                return\n",
    "            else:\n",
    "                samples=random.sample(self.memory,batch_size)\n",
    "                for sample in samples:\n",
    "                    state,action,reward,new_state,done=sample\n",
    "                    target=self.target_model.predict(state)\n",
    "                    if done:\n",
    "                        target[0][action]=reward\n",
    "                    else:\n",
    "                        Q_future=max(self.target_model.predict(new_state)[0])\n",
    "                        target[0][action]=reward+Q_future*self.gamma\n",
    "                    self.model.fit(state,target,epoch=1,verbose=1)\n",
    "    def remember(self,state,action,reward,new_state,done):\n",
    "        self.memory.append([state,action,reward,new_state,done])\n",
    "    def target_train(self):\n",
    "            weights=self.model.get_weights()\n",
    "            target_weights=self.target_model.get_weights()\n",
    "            for i in range(len(target_weights)):\n",
    "                target_weights[i]=weights[i]*self.tau+target_weights[i]*(1-self.tau)\n",
    "            self.target_model.set_weights(target_weights)\n",
    "    def save_model(self,fn):\n",
    "         self.model.save(fn)\n",
    "\n"
   ],
   "id": "a4982454fd72cb22",
   "outputs": [],
   "execution_count": 164
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T15:41:37.895152Z",
     "start_time": "2026-01-11T15:41:37.890620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env=gymnasium.make('MountainCar-v0',render_mode='human')\n",
    "gamma=0.9\n",
    "epsilon=0.95"
   ],
   "id": "c13913a3c20e4eb7",
   "outputs": [],
   "execution_count": 165
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T15:41:38.361616Z",
     "start_time": "2026-01-11T15:41:38.267798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trails=1000\n",
    "trails_len=500\n",
    "dpn_agent=DQN(env=env)"
   ],
   "id": "f801dccce33191dd",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Argument(s) not recognized: {'lr': 0.005}",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[166]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m trails=\u001B[32m1000\u001B[39m\n\u001B[32m      2\u001B[39m trails_len=\u001B[32m500\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m dpn_agent=\u001B[43mDQN\u001B[49m\u001B[43m(\u001B[49m\u001B[43menv\u001B[49m\u001B[43m=\u001B[49m\u001B[43menv\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[164]\u001B[39m\u001B[32m, line 11\u001B[39m, in \u001B[36mDQN.__init__\u001B[39m\u001B[34m(self, env)\u001B[39m\n\u001B[32m      9\u001B[39m \u001B[38;5;28mself\u001B[39m.learning_rate=\u001B[32m0.005\u001B[39m\n\u001B[32m     10\u001B[39m \u001B[38;5;28mself\u001B[39m.tau=\u001B[32m0.125\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m \u001B[38;5;28mself\u001B[39m.model=\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcreate_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     12\u001B[39m \u001B[38;5;28mself\u001B[39m.target_model=\u001B[38;5;28mself\u001B[39m.create_model()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[164]\u001B[39m\u001B[32m, line 19\u001B[39m, in \u001B[36mDQN.create_model\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     17\u001B[39m model.add(Dense(\u001B[32m24\u001B[39m,activation=\u001B[33m'\u001B[39m\u001B[33mrelu\u001B[39m\u001B[33m'\u001B[39m))\n\u001B[32m     18\u001B[39m model.add(Dense(\u001B[38;5;28mself\u001B[39m.env.action_space.n))\n\u001B[32m---> \u001B[39m\u001B[32m19\u001B[39m model.compile(loss=\u001B[33m'\u001B[39m\u001B[33mmean_squared_error\u001B[39m\u001B[33m'\u001B[39m, optimizer=\u001B[43mAdam\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlr\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m     20\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\optimizers\\adam.py:62\u001B[39m, in \u001B[36mAdam.__init__\u001B[39m\u001B[34m(self, learning_rate, beta_1, beta_2, epsilon, amsgrad, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, loss_scale_factor, gradient_accumulation_steps, name, **kwargs)\u001B[39m\n\u001B[32m     43\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__init__\u001B[39m(\n\u001B[32m     44\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m     45\u001B[39m     learning_rate=\u001B[32m0.001\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     60\u001B[39m     **kwargs,\n\u001B[32m     61\u001B[39m ):\n\u001B[32m---> \u001B[39m\u001B[32m62\u001B[39m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[32m     63\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     64\u001B[39m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[43m=\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     65\u001B[39m \u001B[43m        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[43m=\u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     66\u001B[39m \u001B[43m        \u001B[49m\u001B[43mclipnorm\u001B[49m\u001B[43m=\u001B[49m\u001B[43mclipnorm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     67\u001B[39m \u001B[43m        \u001B[49m\u001B[43mclipvalue\u001B[49m\u001B[43m=\u001B[49m\u001B[43mclipvalue\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     68\u001B[39m \u001B[43m        \u001B[49m\u001B[43mglobal_clipnorm\u001B[49m\u001B[43m=\u001B[49m\u001B[43mglobal_clipnorm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     69\u001B[39m \u001B[43m        \u001B[49m\u001B[43muse_ema\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_ema\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     70\u001B[39m \u001B[43m        \u001B[49m\u001B[43mema_momentum\u001B[49m\u001B[43m=\u001B[49m\u001B[43mema_momentum\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     71\u001B[39m \u001B[43m        \u001B[49m\u001B[43mema_overwrite_frequency\u001B[49m\u001B[43m=\u001B[49m\u001B[43mema_overwrite_frequency\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     72\u001B[39m \u001B[43m        \u001B[49m\u001B[43mloss_scale_factor\u001B[49m\u001B[43m=\u001B[49m\u001B[43mloss_scale_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     73\u001B[39m \u001B[43m        \u001B[49m\u001B[43mgradient_accumulation_steps\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgradient_accumulation_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     74\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     75\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     76\u001B[39m     \u001B[38;5;28mself\u001B[39m.beta_1 = beta_1\n\u001B[32m     77\u001B[39m     \u001B[38;5;28mself\u001B[39m.beta_2 = beta_2\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\optimizer.py:21\u001B[39m, in \u001B[36mTFOptimizer.__init__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m     20\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args, **kwargs):\n\u001B[32m---> \u001B[39m\u001B[32m21\u001B[39m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     22\u001B[39m     \u001B[38;5;28mself\u001B[39m._distribution_strategy = tf.distribute.get_strategy()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:90\u001B[39m, in \u001B[36mBaseOptimizer.__init__\u001B[39m\u001B[34m(self, learning_rate, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, loss_scale_factor, gradient_accumulation_steps, name, **kwargs)\u001B[39m\n\u001B[32m     86\u001B[39m     warnings.warn(\n\u001B[32m     87\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mArgument `decay` is no longer supported and will be ignored.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     88\u001B[39m     )\n\u001B[32m     89\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m kwargs:\n\u001B[32m---> \u001B[39m\u001B[32m90\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mArgument(s) not recognized: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkwargs\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     92\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m     93\u001B[39m     name = auto_name(\u001B[38;5;28mself\u001B[39m.\u001B[34m__class__\u001B[39m.\u001B[34m__name__\u001B[39m)\n",
      "\u001B[31mValueError\u001B[39m: Argument(s) not recognized: {'lr': 0.005}"
     ]
    }
   ],
   "execution_count": 166
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T15:22:01.694784Z",
     "start_time": "2026-01-11T15:22:01.629552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "steps=[]\n",
    "for trail in range(trails):\n",
    "    current_state=env.reset().reshape(1,2)\n",
    "    for step in range(trails_len):\n",
    "        print('#',step)\n",
    "        action=dpn_agent.act(current_state)\n",
    "        new_state,reward,done,_=env.step(action)\n",
    "        new_state=new_state.reshape(1,2)\n",
    "        dqn_agent.remember(current_state,action,reward,new_state,done)\n",
    "        dqn_agnet.replay(current_state)\n",
    "        dqn_agnet.target_train()\n",
    "        current_state=new_state\n",
    "        if done:\n",
    "            break\n",
    "        if steps>=199:\n",
    "            print('faild')\n",
    "        else:\n",
    "            print('success')\n",
    "            dqn_agnet.save_model('parnia')\n",
    "            break"
   ],
   "id": "91dd4ee42d4fb8ff",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[153]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m steps=[]\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m trail \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(trails):\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m     current_state=\u001B[43menv\u001B[49m\u001B[43m.\u001B[49m\u001B[43mreset\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mreshape\u001B[49m(\u001B[32m1\u001B[39m,\u001B[32m2\u001B[39m)\n\u001B[32m      4\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(trails_len):\n\u001B[32m      5\u001B[39m         action=dpn_agent.act(current_state)\n",
      "\u001B[31mAttributeError\u001B[39m: 'tuple' object has no attribute 'reshape'"
     ]
    }
   ],
   "execution_count": 153
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d057ddd5e2de985e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "940bc77923ed1fda"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c7d25e46cef36d20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ccaa38f3d98cd7c2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
