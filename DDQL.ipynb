{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T06:58:42.280599Z",
     "start_time": "2026-01-21T06:58:42.275915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "import gym\n",
    "import gymnasium\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from collections import deque\n",
    "\n",
    "from tensorflow.python.ops.gen_batch_ops import batch"
   ],
   "id": "410799553c184655",
   "outputs": [],
   "execution_count": 142
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T06:58:42.491113Z",
     "start_time": "2026-01-21T06:58:42.487037Z"
    }
   },
   "cell_type": "code",
   "source": "env=gymnasium.make('MountainCar-v0',render_mode='human')",
   "id": "27cedc4d7c0b9a9",
   "outputs": [],
   "execution_count": 143
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T06:58:42.707372Z",
     "start_time": "2026-01-21T06:58:42.667497Z"
    }
   },
   "cell_type": "code",
   "source": "env.reset()",
   "id": "2aa4932b7742d606",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.50068897,  0.        ], dtype=float32), {})"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 144
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T06:58:42.863076Z",
     "start_time": "2026-01-21T06:58:42.858515Z"
    }
   },
   "cell_type": "code",
   "source": "env.render()",
   "id": "37afb5c9ed53050",
   "outputs": [],
   "execution_count": 145
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T06:58:43.048902Z",
     "start_time": "2026-01-21T06:58:43.044809Z"
    }
   },
   "cell_type": "code",
   "source": "env.observation_space.shape[0]",
   "id": "a162bb263a98a831",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 146
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T06:58:43.511547Z",
     "start_time": "2026-01-21T06:58:43.507159Z"
    }
   },
   "cell_type": "code",
   "source": "env.action_space.n\n",
   "id": "224a5ab6a1cb5f29",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(3)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 147
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T06:58:43.894277Z",
     "start_time": "2026-01-21T06:58:43.890702Z"
    }
   },
   "cell_type": "code",
   "source": "env.action_space.sample()",
   "id": "60ff8c49c8d15bb3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 148
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T06:58:44.292053Z",
     "start_time": "2026-01-21T06:58:44.282667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DQN:\n",
    "    def __init__(self,env):\n",
    "        self.env=env\n",
    "        self.memory=deque(maxlen=2000)\n",
    "        self.gamma=0.99\n",
    "        self.epsilon=1.0\n",
    "        self.epsilon_min=0.01\n",
    "        self.epsilon_decay=0.995\n",
    "        self.learning_rate=0.005\n",
    "        self.tau=0.125\n",
    "        self.model=self.create_model()\n",
    "        self.target_model=self.create_model()\n",
    "    def create_model(self):\n",
    "            model=Sequential()\n",
    "            model.add(Dense(24,input_dim=self.env.observation_space.shape[0],activation='relu'))\n",
    "            model.add(Dense(48,activation='relu'))\n",
    "            model.add(Dense(24,activation='relu'))\n",
    "            model.add(Dense(self.env.action_space.n))\n",
    "            model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=self.learning_rate))\n",
    "            return model\n",
    "    def act(self,state):\n",
    "            if np.random.random()<self.epsilon:\n",
    "                return  self.env.action_space.sample()\n",
    "            else:\n",
    "                state=np.array(state,dtype=np.float32).reshape(1,-1)\n",
    "                return np.argmax(self.model.predict(state,verbose=0))\n",
    "    def replay(self, batch_size=32):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "\n",
    "        samples = random.sample(self.memory, batch_size)\n",
    "        states = np.vstack([s[0] for s in samples])\n",
    "        targets = self.model.predict(states, verbose=0)\n",
    "        for i, sample in enumerate(samples):\n",
    "            state, action, reward, new_state, done = sample\n",
    "            if done:\n",
    "                targets[i][action] = reward\n",
    "            else:\n",
    "                Q_future = max(self.target_model.predict(new_state, verbose=0)[0])\n",
    "                targets[i][action] = reward + self.gamma * Q_future\n",
    "\n",
    "        self.model.fit(states, targets, epochs=1, verbose=0)\n",
    "    def remember(self,state,action,reward,new_state,done):\n",
    "        self.memory.append([state,action,reward,new_state,done])\n",
    "    def target_train(self):\n",
    "            weights=self.model.get_weights()\n",
    "            target_weights=self.target_model.get_weights()\n",
    "            for i in range(len(target_weights)):\n",
    "                target_weights[i]=weights[i]*self.tau+target_weights[i]*(1-self.tau)\n",
    "            self.target_model.set_weights(target_weights)\n",
    "    def save_model(self,fn):\n",
    "         self.model.save(fn)\n",
    "\n"
   ],
   "id": "a4982454fd72cb22",
   "outputs": [],
   "execution_count": 149
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T06:58:44.713740Z",
     "start_time": "2026-01-21T06:58:44.709731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env=gymnasium.make('MountainCar-v0',render_mode='human')\n",
    "gamma=0.9\n",
    "epsilon=0.95"
   ],
   "id": "c13913a3c20e4eb7",
   "outputs": [],
   "execution_count": 150
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T06:58:45.090730Z",
     "start_time": "2026-01-21T06:58:45.048616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trails=200\n",
    "trails_len=100\n",
    "dpn_agent=DQN(env=env)"
   ],
   "id": "f801dccce33191dd",
   "outputs": [],
   "execution_count": 151
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2026-01-21T06:58:45.581277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "steps=[]\n",
    "batch_size=50\n",
    "for episode in range(trails):\n",
    "    current_state,_=env.reset()\n",
    "    current_state=current_state.reshape(1,2)\n",
    "    steps_count=0\n",
    "    total_reward=0\n",
    "    for step in range(trails_len):\n",
    "        steps_count+=1\n",
    "        action=dpn_agent.act(current_state)\n",
    "        new_state,reward,terminated,truncated,_=env.step(action)\n",
    "        done= truncated or terminated\n",
    "        new_state=new_state.reshape(1,2)\n",
    "        dpn_agent.remember(current_state,action,reward,new_state,done)\n",
    "        dpn_agent.replay(batch_size=batch_size)\n",
    "        dpn_agent.target_train()\n",
    "        current_state=new_state\n",
    "        total_reward += reward\n",
    "        print(f\"\\rEpisode {episode+1} Step {steps_count}\", end=\"\")\n",
    "        if done:\n",
    "            break\n",
    "    dpn_agent.epsilon = max(dpn_agent.epsilon_min, dpn_agent.epsilon * dpn_agent.epsilon_decay)\n",
    "    print(f\"Episode {episode+1}/{trails} Steps: {steps_count}  Total reward: {total_reward:.2f} Epsilon: {dpn_agent.epsilon:.2f}\")\n",
    "    dpn_agent.save_model('parnia.keras')\n",
    "\n",
    "    if dpn_agent.epsilon > dpn_agent.epsilon_min:\n",
    "        dpn_agent.epsilon *= dpn_agent.epsilon_decay"
   ],
   "id": "91dd4ee42d4fb8ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 Step 49"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "729ce2505b191bd8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
